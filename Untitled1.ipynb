{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6efd3600-1637-401b-8d3c-2e69b697e093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.24.1)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy\n",
      "  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (164 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.5/164.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, scipy, kiwisolver, fonttools, cycler, contourpy, pandas, matplotlib, seaborn\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.0 kiwisolver-1.4.7 matplotlib-3.9.2 pandas-2.2.3 pytz-2024.2 scipy-1.14.1 seaborn-0.13.2 tzdata-2024.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting PyMuPDF\n",
      "  Downloading PyMuPDF-1.24.13-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
      "Downloading PyMuPDF-1.24.13-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.24.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m678.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.2->transformers)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Downloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, safetensors, regex, fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed fsspec-2024.10.0 huggingface-hub-0.26.2 regex-2024.11.6 safetensors-0.4.5 tokenizers-0.20.3 tqdm-4.67.0 transformers-4.46.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting pythainlp\n",
      "  Downloading pythainlp-5.0.4-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pythainlp) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2022.12.7)\n",
      "Downloading pythainlp-5.0.4-py3-none-any.whl (17.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.9/17.9 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pythainlp\n",
      "Successfully installed pythainlp-5.0.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.49-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.24.1)\n",
      "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.31.0)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.3)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.11.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2024.2)\n",
      "Collecting frozendict>=2.3.4 (from yfinance)\n",
      "  Downloading frozendict-2.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Downloading peewee-3.17.8.tar.gz (948 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.2/948.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.2)\n",
      "Collecting html5lib>=1.1 (from yfinance)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in /usr/lib/python3/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2022.12.7)\n",
      "Downloading yfinance-0.2.49-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.1/101.1 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozendict-2.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Building wheels for collected packages: peewee\n",
      "  Building wheel for peewee (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for peewee: filename=peewee-3.17.8-py3-none-any.whl size=138965 sha256=829a16d44cf2b3355446444940197faf78fc1b75083a41bdcd0b041c7e225325\n",
      "  Stored in directory: /root/.cache/pip/wheels/75/79/e5/8838db0594cc6c587142fd2563356392ade6255c5930411069\n",
      "Successfully built peewee\n",
      "Installing collected packages: peewee, multitasking, html5lib, frozendict, yfinance\n",
      "Successfully installed frozendict-2.4.6 html5lib-1.1 multitasking-0.0.11 peewee-3.17.8 yfinance-0.2.49\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.3.0)\n",
      "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2022.12.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.24.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.14.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
      "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.24.13)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
      "Requirement already satisfied: pythainlp in /usr/local/lib/python3.10/dist-packages (5.0.4)\n",
      "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.49)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.3.0)\n",
      "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.3)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.11.0)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.2)\n",
      "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in /usr/lib/python3/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Core data science packages\n",
    "!pip install numpy pandas scipy matplotlib seaborn\n",
    "\n",
    "# PDF processing\n",
    "\n",
    "!pip install PyMuPDF\n",
    "\n",
    "# Machine Learning & NLP\n",
    "!pip install transformers\n",
    "!pip install pythainlp\n",
    "\n",
    "# Financial data\n",
    "!pip install yfinance\n",
    "\n",
    "# Image processing\n",
    "!pip install Pillow\n",
    "!pip install pytesseract\n",
    "\n",
    "# HTTP requests\n",
    "!pip install requests\n",
    "\n",
    "# Optional: Install all packages in one line\n",
    "!pip install numpy pandas scipy matplotlib seaborn PyMuPDF transformers pythainlp yfinance Pillow pytesseract requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc8eda68-f7fe-4c51-8ff3-0fdec359d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TYPHOON_API_KEY'] = 'sk-oHvFDpRkCC1dCMwOvMqInFpCRWJqvgk3sVASJ6k00ys3fVl8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cac19abd-125f-4dfc-85f6-4dfa2a1280db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33d70bb0-5e14-476e-9581-9bb5a1b3b195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "กำลังโหลดโมเดลจำแนกประเภท...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at joeddav/xlm-roberta-large-xnli were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\n requires the protobuf library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:1496\u001b[0m, in \u001b[0;36mTikTokenConverter.extract_vocab_merges_from_model\u001b[0;34m(self, tiktoken_url)\u001b[0m\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1496\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtiktoken\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_tiktoken_bpe\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tiktoken'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:1636\u001b[0m, in \u001b[0;36mconvert_slow_tokenizer\u001b[0;34m(transformer_tokenizer, from_tiktoken)\u001b[0m\n\u001b[1;32m   1632\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting from Tiktoken\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTikTokenConverter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformer_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformer_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madditional_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:1533\u001b[0m, in \u001b[0;36mTikTokenConverter.converted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconverted\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tokenizer:\n\u001b[0;32m-> 1533\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1534\u001b[0m     tokenizer\u001b[38;5;241m.\u001b[39mpre_tokenizer \u001b[38;5;241m=\u001b[39m pre_tokenizers\u001b[38;5;241m.\u001b[39mSequence(\n\u001b[1;32m   1535\u001b[0m         [\n\u001b[1;32m   1536\u001b[0m             pre_tokenizers\u001b[38;5;241m.\u001b[39mSplit(Regex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpattern), behavior\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misolated\u001b[39m\u001b[38;5;124m\"\u001b[39m, invert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1537\u001b[0m             pre_tokenizers\u001b[38;5;241m.\u001b[39mByteLevel(add_prefix_space\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space, use_regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1538\u001b[0m         ]\n\u001b[1;32m   1539\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:1526\u001b[0m, in \u001b[0;36mTikTokenConverter.tokenizer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenizer\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1526\u001b[0m     vocab_scores, merges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_vocab_merges_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1527\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m Tokenizer(BPE(vocab_scores, merges, fuse_unk\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:1498\u001b[0m, in \u001b[0;36mTikTokenConverter.extract_vocab_merges_from_model\u001b[0;34m(self, tiktoken_url)\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m-> 1498\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tiktoken` is required to read a `tiktoken` file. Install it with \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tiktoken`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1500\u001b[0m     )\n\u001b[1;32m   1502\u001b[0m bpe_ranks \u001b[38;5;241m=\u001b[39m load_tiktoken_bpe(tiktoken_url)\n",
      "\u001b[0;31mValueError\u001b[0m: `tiktoken` is required to read a `tiktoken` file. Install it with `pip install tiktoken`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2447\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2446\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2447\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2448\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m import_protobuf_decode_error():\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/xlm_roberta/tokenization_xlm_roberta_fast.py:108\u001b[0m, in \u001b[0;36mXLMRobertaTokenizerFast.__init__\u001b[0;34m(self, vocab_file, tokenizer_file, bos_token, eos_token, sep_token, cls_token, unk_token, pad_token, mask_token, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m mask_token \u001b[38;5;241m=\u001b[39m AddedToken(mask_token, lstrip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rstrip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mask_token, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m mask_token\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcls_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcls_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43munk_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munk_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_file \u001b[38;5;241m=\u001b[39m vocab_file\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_fast.py:138\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madditional_special_tokens \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditional_special_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n\u001b[0;32m--> 138\u001b[0m fast_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_slow_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_tiktoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m slow_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:1638\u001b[0m, in \u001b[0;36mconvert_slow_tokenizer\u001b[0;34m(transformer_tokenizer, from_tiktoken)\u001b[0m\n\u001b[1;32m   1637\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m-> 1638\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1639\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1640\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith a SentencePiece tokenizer.model file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1641\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently available slow->fast convertors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(SLOW_TO_FAST_CONVERTERS\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1642\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 557\u001b[0m\n\u001b[1;32m    554\u001b[0m api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m65322b83-2986-4471-8efd-43a761d49aad\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# ใช้ API Key ที่คุณมี\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;66;03m# สร้างอินสแตนซ์ของ AdvancedFinancialAnalyzer\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m analyzer \u001b[38;5;241m=\u001b[39m \u001b[43mAdvancedFinancialAnalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# ระบุเส้นทางไปยังไฟล์ PDF ของคุณ\u001b[39;00m\n\u001b[1;32m    560\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# เปลี่ยนเป็นเส้นทางไฟล์ PDF ที่คุณต้องการวิเคราะห์\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 118\u001b[0m, in \u001b[0;36mAdvancedFinancialAnalyzer.__init__\u001b[0;34m(self, api_key)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mกำลังโหลดโมเดลจำแนกประเภท...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# ปรับปรุงการโหลดโมเดลและ tokenizer\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzero-shot-classification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjoeddav/xlm-roberta-large-xnli\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjoeddav/xlm-roberta-large-xnli\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m    123\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarket_data \u001b[38;5;241m=\u001b[39m MarketData(api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/__init__.py:1033\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m             tokenizer_kwargs \u001b[38;5;241m=\u001b[39m model_kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m   1031\u001b[0m             tokenizer_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1033\u001b[0m         tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokenizer_identifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_fast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_from_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtokenizer_kwargs\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_image_processor:\n\u001b[1;32m   1038\u001b[0m     \u001b[38;5;66;03m# Try to infer image processor from model or config name (if provided as str)\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m image_processor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:939\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    936\u001b[0m tokenizer_class_py, tokenizer_class_fast \u001b[38;5;241m=\u001b[39m TOKENIZER_MAPPING[\u001b[38;5;28mtype\u001b[39m(config)]\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_fast \u001b[38;5;129;01mand\u001b[39;00m (use_fast \u001b[38;5;129;01mor\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 939\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class_fast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2213\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2210\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2211\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolved_vocab_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_is_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2224\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2448\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2446\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2447\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39minit_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minit_kwargs)\n\u001b[0;32m-> 2448\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[43mimport_protobuf_decode_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   2449\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   2450\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load tokenizer model from SPM, loading from TikToken will be attempted instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2451\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Google protobuf error: Tried to load SPM model with non-SPM vocab file).\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2452\u001b[0m     )\n\u001b[1;32m   2453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:87\u001b[0m, in \u001b[0;36mimport_protobuf_decode_error\u001b[0;34m(error_message)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DecodeError\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(PROTOBUF_IMPORT_ERROR\u001b[38;5;241m.\u001b[39mformat(error_message))\n",
      "\u001b[0;31mImportError\u001b[0m: \n requires the protobuf library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "from transformers import pipeline\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Optional, Tuple, List, Any\n",
    "from dataclasses import dataclass\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import io\n",
    "\n",
    "import pythainlp\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.util import normalize\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Data Classes\n",
    "@dataclass\n",
    "class FinancialMetrics:\n",
    "    basic_metrics: Dict[str, float]\n",
    "    technical_indicators: Dict[str, Any]\n",
    "    risk_metrics: Dict[str, float]\n",
    "    statistical_metrics: Dict[str, Any]\n",
    "\n",
    "@dataclass\n",
    "class IndustryAnalysis:\n",
    "    industry_type: str\n",
    "    key_indicators: List[str]\n",
    "    study_topics: List[str]\n",
    "    peer_companies: List[str]\n",
    "    industry_metrics: Dict[str, float]\n",
    "\n",
    "@dataclass\n",
    "class FinancialData:\n",
    "    symbol: str\n",
    "    prices: np.ndarray\n",
    "    returns: np.ndarray\n",
    "    dates: np.ndarray\n",
    "    volume: np.ndarray\n",
    "    market_cap: float\n",
    "    sector: str\n",
    "    financial_metrics: Optional[FinancialMetrics] = None\n",
    "\n",
    "class MarketData:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.market_index = \"^SET\"  # ปรับให้ตรงกับ SET Index\n",
    "        self.cache = {}\n",
    "        self.api_key = api_key\n",
    "        self.base_url = 'https://www.setsmart.com/api/listed-company-api'\n",
    "        self.headers = {'api-key': self.api_key}\n",
    "\n",
    "    def get_stock_data(self, symbol: str, start_date: str, end_date: str) -> Optional[FinancialData]:\n",
    "        print(f\"\\nดึงข้อมูลหุ้นสำหรับ {symbol}\")\n",
    "        try:\n",
    "            if symbol in self.cache:\n",
    "                print(f\"ใช้ข้อมูลที่แคชไว้สำหรับ {symbol}\")\n",
    "                return self.cache[symbol]\n",
    "\n",
    "            # ดึงข้อมูลราคาหุ้นจาก SET SMART API\n",
    "            url = f'{self.base_url}/eod-price-by-symbol'\n",
    "            params = {\n",
    "                'symbol': symbol,\n",
    "                'startDate': start_date,\n",
    "                'endDate': end_date,\n",
    "                'adjustedPriceFlag': 'Y'\n",
    "            }\n",
    "            response = requests.get(url, headers=self.headers, params=params)\n",
    "            data_json = response.json()\n",
    "\n",
    "            if not data_json:\n",
    "                raise ValueError(f\"ไม่พบข้อมูลสำหรับ {symbol}\")\n",
    "\n",
    "            # สร้าง DataFrame จากข้อมูลที่ได้\n",
    "            df = pd.DataFrame(data_json)\n",
    "            df['trading_date'] = pd.to_datetime(df['trading_date'])\n",
    "            df.sort_values('trading_date', inplace=True)\n",
    "\n",
    "            # ดึงข้อมูลเพิ่มเติม เช่น Market Cap, Sector จากอีก API หนึ่ง (ถ้ามี)\n",
    "            # ในที่นี้จะใส่ค่าเป็น 0 หรือ 'Unknown' ไปก่อน\n",
    "            market_cap = 0  # ต้องดึงจาก API ที่ให้ข้อมูลนี้\n",
    "            sector = 'Unknown'  # ต้องดึงจาก API ที่ให้ข้อมูลนี้\n",
    "\n",
    "            data = FinancialData(\n",
    "                symbol=symbol,\n",
    "                prices=df['close_price'].values,\n",
    "                returns=df['close_price'].pct_change().dropna().values,\n",
    "                dates=df['trading_date'].values,\n",
    "                volume=df['total_volume'].values,\n",
    "                market_cap=market_cap,\n",
    "                sector=sector\n",
    "            )\n",
    "\n",
    "            self.cache[symbol] = data\n",
    "            print(f\"ดึงข้อมูลสำเร็จสำหรับ {symbol}\")\n",
    "            return data\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {symbol}: {e}\")\n",
    "            return None\n",
    "\n",
    "class AdvancedFinancialAnalyzer:\n",
    "    def __init__(self, api_key: Optional[str] = None):\n",
    "        self.api_key = api_key\n",
    "        print(\"กำลังโหลดโมเดลจำแนกประเภท...\")\n",
    "\n",
    "        # ปรับปรุงการโหลดโมเดลและ tokenizer\n",
    "        self.classifier = pipeline(\n",
    "            \"zero-shot-classification\",\n",
    "            model=\"joeddav/xlm-roberta-large-xnli\",\n",
    "            tokenizer=\"joeddav/xlm-roberta-large-xnli\",\n",
    "            device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        )\n",
    "\n",
    "        if self.api_key:\n",
    "            self.market_data = MarketData(api_key=self.api_key)\n",
    "        else:\n",
    "            self.market_data = None\n",
    "\n",
    "    def extract_text_from_pdf(self, file_path: str) -> Optional[str]:\n",
    "        \"\"\"Extract and clean text from PDF\"\"\"\n",
    "        print(f\"\\nกำลังดึงข้อความจากไฟล์ PDF: {file_path}\")\n",
    "        try:\n",
    "            text = \"\"\n",
    "            with fitz.open(file_path) as pdf:\n",
    "                for page_num in range(len(pdf)):\n",
    "                    page = pdf[page_num]\n",
    "                    page_text = page.get_text()\n",
    "                    if page_text.strip():\n",
    "                        # ถ้ามีข้อความอยู่แล้ว\n",
    "                        text += page_text\n",
    "                    else:\n",
    "                        # ถ้าไม่มีข้อความ ให้ใช้ OCR\n",
    "                        pix = page.get_pixmap()\n",
    "                        img_data = pix.tobytes(\"png\")\n",
    "                        img = Image.open(io.BytesIO(img_data))\n",
    "                        ocr_text = pytesseract.image_to_string(img, lang='tha+eng')\n",
    "                        text += ocr_text\n",
    "            cleaned_text = self._clean_text(text) if text else None\n",
    "            print(\"\\nข้อความหลังทำความสะอาด:\")\n",
    "            print(cleaned_text[:500])  # แสดงข้อความที่ทำความสะอาดแล้ว (500 ตัวอักษรแรก)\n",
    "            return cleaned_text\n",
    "        except Exception as e:\n",
    "            print(f\"PDF extraction error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean and normalize text while preserving important financial information\"\"\"\n",
    "        print(\"\\nกำลังทำความสะอาดข้อความ...\")\n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "        # Preserve financial numbers and symbols and Thai characters\n",
    "        # Remove unwanted characters but preserve Thai characters and common punctuation\n",
    "        text = re.sub(r'[^\\w\\s$.,%-]', '', text, flags=re.UNICODE)\n",
    "\n",
    "        # Normalize numerical formats\n",
    "        text = re.sub(r'(\\d),(\\d)', r'\\1\\2', text)\n",
    "        print(\"ทำความสะอาดข้อความสำเร็จ\")\n",
    "        return text.strip()\n",
    "\n",
    "    def find_stock_symbol(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Find stock symbol using regex\"\"\"\n",
    "        print(\"\\nกำลังค้นหาสัญลักษณ์หุ้นจากข้อความ...\")\n",
    "        # ใช้ regex เพื่อค้นหาสัญลักษณ์หุ้นในข้อความ\n",
    "        pattern = r'\\b[A-Z]{1,5}\\b'\n",
    "        matches = re.findall(pattern, text)\n",
    "        if matches:\n",
    "            symbol = matches[0]\n",
    "            print(f\"\\nพบสัญลักษณ์หุ้น: {symbol}\")\n",
    "            return symbol\n",
    "        else:\n",
    "            print(\"ไม่พบสัญลักษณ์หุ้นในข้อความ\")\n",
    "            return None\n",
    "\n",
    "    def analyze_company(self, text: str) -> Tuple[str, Dict[str, Any]]:\n",
    "        \"\"\"Comprehensive company analysis\"\"\"\n",
    "        # Try to find stock symbol\n",
    "        symbol = self.find_stock_symbol(text)\n",
    "        if not symbol:\n",
    "            print(\"ไม่สามารถระบุสัญลักษณ์หุ้นได้\")\n",
    "            stock_data = None\n",
    "        else:\n",
    "            # Get market data\n",
    "            # กำหนดวันที่เริ่มต้นและสิ้นสุดสำหรับการดึงข้อมูล\n",
    "            end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "            start_date = (datetime.now() - pd.DateOffset(years=1)).strftime('%Y-%m-%d')\n",
    "            stock_data = self.market_data.get_stock_data(symbol, start_date, end_date)\n",
    "            if stock_data is None:\n",
    "                print(f\"ไม่สามารถดึงข้อมูลหุ้น {symbol} ได้\")\n",
    "\n",
    "        # Industry Classification\n",
    "        industry = self._classify_industry(text)\n",
    "\n",
    "        # เพิ่มการแนะนำหลังจากจำแนกประเภทธุรกิจ\n",
    "        print(f\"\\nบริษัทนี้อยู่ในอุตสาหกรรม: {industry}\")\n",
    "        print(\"คุณควรศึกษาปัจจัยเฉพาะของอุตสาหกรรมนี้เพิ่มเติมเพื่อการตัดสินใจลงทุน\")\n",
    "\n",
    "        # Calculate financial metrics if stock data is available\n",
    "        if stock_data:\n",
    "            financial_metrics = self._calculate_financial_metrics(stock_data)\n",
    "        else:\n",
    "            financial_metrics = None\n",
    "\n",
    "        # Industry analysis\n",
    "        industry_analysis = self._analyze_industry_specifics(text, industry, symbol)\n",
    "\n",
    "        # Get AI recommendations (ถ้ามีการใช้งาน Typhoon API)\n",
    "        ai_analysis = {}\n",
    "\n",
    "        return industry, {\n",
    "            'symbol': symbol,\n",
    "            'financial_metrics': financial_metrics,\n",
    "            'industry_analysis': industry_analysis,\n",
    "            'ai_recommendations': ai_analysis,\n",
    "            'stock_data': stock_data\n",
    "        }\n",
    "\n",
    "    def _classify_industry(self, text: str) -> str:\n",
    "        \"\"\"Classify company industry using zero-shot classification\"\"\"\n",
    "        print(\"\\nกำลังจำแนกประเภทอุตสาหกรรม...\")\n",
    "        dynamic_labels = ['ธนาคาร', 'ก่อสร้าง', 'เทคโนโลยี', 'สุขภาพ', 'พลังงาน', 'อสังหาริมทรัพย์',\n",
    "                          'การขนส่ง', 'การสื่อสาร', 'การเกษตร', 'อาหาร', 'การท่องเที่ยว',\n",
    "                          'ค้าปลีก', 'การผลิต', 'การเงิน', 'สื่อ', 'บันเทิง', 'เคมีภัณฑ์']\n",
    "        result = self.classifier(\n",
    "            sequences=text[:512],\n",
    "            candidate_labels=dynamic_labels,\n",
    "            hypothesis_template=\"นี่คือข้อความเกี่ยวกับ {}.\",\n",
    "            multi_label=False\n",
    "        )\n",
    "        industry = result['labels'][0]\n",
    "        print(f\"\\nประเภทอุตสาหกรรมที่จำแนกได้: {industry}\")\n",
    "        return industry\n",
    "\n",
    "    def _calculate_financial_metrics(self, stock_data: FinancialData) -> FinancialMetrics:\n",
    "        \"\"\"Calculate comprehensive financial metrics\"\"\"\n",
    "        print(\"\\nกำลังคำนวณตัวชี้วัดทางการเงิน...\")\n",
    "        prices = stock_data.prices\n",
    "        returns = stock_data.returns\n",
    "\n",
    "        financial_metrics = FinancialMetrics(\n",
    "            basic_metrics=self._calculate_basic_metrics(stock_data),\n",
    "            technical_indicators=self._calculate_technical_indicators(prices),\n",
    "            risk_metrics=self._calculate_risk_metrics(returns),\n",
    "            statistical_metrics=self._calculate_statistical_metrics(returns)\n",
    "        )\n",
    "        print(\"\\nคำนวณตัวชี้วัดทางการเงินสำเร็จ\")\n",
    "        return financial_metrics\n",
    "\n",
    "    def _calculate_basic_metrics(self, stock_data: FinancialData) -> Dict[str, float]:\n",
    "        \"\"\"Calculate basic financial ratios\"\"\"\n",
    "        print(\" - กำลังคำนวณอัตราส่วนทางการเงินพื้นฐาน...\")\n",
    "        try:\n",
    "            current_price = stock_data.prices[-1]\n",
    "            eps = self._get_eps(stock_data.symbol)\n",
    "            bvps = self._get_book_value(stock_data.symbol)\n",
    "            net_income = self._get_net_income(stock_data.symbol)\n",
    "            equity = self._get_equity(stock_data.symbol)\n",
    "            basic_metrics = {\n",
    "                'price': current_price,\n",
    "                'market_cap': stock_data.market_cap,\n",
    "                'pe_ratio': self._safe_calc(lambda: current_price / eps if eps != 0 else None),\n",
    "                'pb_ratio': self._safe_calc(lambda: current_price / bvps if bvps != 0 else None),\n",
    "                'roe': self._safe_calc(lambda: net_income / equity if equity != 0 else None)\n",
    "            }\n",
    "            print(f\"\\nอัตราส่วนทางการเงินพื้นฐาน: {basic_metrics}\")\n",
    "            return basic_metrics\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating basic metrics: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def _calculate_technical_indicators(self, prices: np.ndarray) -> Dict[str, Any]:\n",
    "        \"\"\"Calculate technical analysis indicators\"\"\"\n",
    "        print(\" - กำลังคำนวณตัวชี้วัดทางเทคนิค...\")\n",
    "        try:\n",
    "            technical_indicators = {\n",
    "                'rsi': self._calculate_rsi(prices),\n",
    "                'macd': self._calculate_macd(prices),\n",
    "                'bollinger_bands': self._calculate_bollinger_bands(prices),\n",
    "                'moving_averages': {\n",
    "                    'ma20': np.mean(prices[-20:]),\n",
    "                    'ma50': np.mean(prices[-50:]),\n",
    "                    'ma200': np.mean(prices[-200:])\n",
    "                }\n",
    "            }\n",
    "            print(f\"\\nตัวชี้วัดทางเทคนิค: {technical_indicators}\")\n",
    "            return technical_indicators\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating technical indicators: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def _calculate_risk_metrics(self, returns: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"Calculate risk and performance metrics\"\"\"\n",
    "        print(\" - กำลังคำนวณตัวชี้วัดความเสี่ยง...\")\n",
    "        try:\n",
    "            risk_metrics = {\n",
    "                'volatility': np.std(returns) * np.sqrt(252),\n",
    "                'var_95': np.percentile(returns, 5),\n",
    "                'cvar_95': np.mean(returns[returns <= np.percentile(returns, 5)]),\n",
    "                'sharpe_ratio': np.mean(returns) / np.std(returns) * np.sqrt(252),\n",
    "                'sortino_ratio': np.mean(returns) / np.std(returns[returns < 0]) * np.sqrt(252)\n",
    "            }\n",
    "            print(f\"\\nตัวชี้วัดความเสี่ยง: {risk_metrics}\")\n",
    "            return risk_metrics\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating risk metrics: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def _calculate_statistical_metrics(self, returns: np.ndarray) -> Dict[str, Any]:\n",
    "        \"\"\"Calculate statistical properties\"\"\"\n",
    "        print(\" - กำลังคำนวณตัวชี้วัดสถิติ...\")\n",
    "        try:\n",
    "            # Stationarity test\n",
    "            adf_stat, adf_pvalue = stats.adfuller(returns)[:2]\n",
    "\n",
    "            # Normality tests\n",
    "            shapiro_stat, shapiro_pvalue = stats.shapiro(returns)\n",
    "\n",
    "            statistical_metrics = {\n",
    "                'stationarity': {\n",
    "                    'adf_statistic': adf_stat,\n",
    "                    'adf_pvalue': adf_pvalue\n",
    "                },\n",
    "                'normality': {\n",
    "                    'shapiro_statistic': shapiro_stat,\n",
    "                    'shapiro_pvalue': shapiro_pvalue\n",
    "                },\n",
    "                'skewness': stats.skew(returns),\n",
    "                'kurtosis': stats.kurtosis(returns)\n",
    "            }\n",
    "            print(f\"\\nตัวชี้วัดสถิติ: {statistical_metrics}\")\n",
    "            return statistical_metrics\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating statistical metrics: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def _analyze_industry_specifics(self, text: str, industry: str, symbol: Optional[str]) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze industry-specific factors\"\"\"\n",
    "        print(\"\\nกำลังวิเคราะห์ปัจจัยเฉพาะของอุตสาหกรรม...\")\n",
    "        peer_companies = self._find_similar_companies(industry, symbol)\n",
    "        if symbol and symbol in peer_companies:\n",
    "            peer_companies.remove(symbol)  # เอาบริษัทที่เราวิเคราะห์ออก\n",
    "\n",
    "        return {\n",
    "            'study_topics': self._get_study_topics(industry),\n",
    "            'peer_companies': peer_companies,\n",
    "        }\n",
    "\n",
    "    def _find_similar_companies(self, industry: str, symbol: Optional[str]) -> List[str]:\n",
    "        \"\"\"Find similar companies in the same industry\"\"\"\n",
    "        print(\"\\nกำลังหาบริษัทที่คล้ายกันในอุตสาหกรรมเดียวกัน...\")\n",
    "        # สำหรับตัวอย่างนี้ จะคืนค่าเป็นลิสต์ของสัญลักษณ์หุ้นที่กำหนดเอง\n",
    "        industry_peers = {\n",
    "            'ธนาคาร': ['BBL', 'KBANK', 'SCB'],\n",
    "            'พลังงาน': ['PTT', 'PTTEP', 'TOP'],\n",
    "            # เพิ่มเติมตามต้องการ\n",
    "        }\n",
    "        return industry_peers.get(industry, [])\n",
    "\n",
    "    def _get_study_topics(self, industry: str) -> List[str]:\n",
    "        \"\"\"Get study topics based on industry\"\"\"\n",
    "        topics = {\n",
    "            'ธนาคาร': ['การจัดการความเสี่ยงทางการเงิน', 'กฎระเบียบของธนาคารกลาง'],\n",
    "            'เทคโนโลยี': ['นวัตกรรมใหม่', 'การแข่งขันในตลาด'],\n",
    "            # เพิ่มหัวข้อสำหรับอุตสาหกรรมอื่นๆ ตามต้องการ\n",
    "        }\n",
    "        return topics.get(industry, ['ศึกษาภาพรวมของอุตสาหกรรมเพิ่มเติม'])\n",
    "\n",
    "    # ฟังก์ชัน Helper\n",
    "    def _safe_calc(self, func):\n",
    "        \"\"\"Safely execute calculation\"\"\"\n",
    "        try:\n",
    "            return func()\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    # ฟังก์ชันสำหรับดึงข้อมูลทางการเงินจาก SET SMART API\n",
    "    def _get_eps(self, symbol: str) -> float:\n",
    "        \"\"\"Fetch EPS for the stock symbol\"\"\"\n",
    "        url = f'{self.market_data.base_url}/financial-data-and-ratio-by-symbol'\n",
    "        params = {\n",
    "            'symbol': symbol,\n",
    "            'startYear': datetime.now().year,\n",
    "            'startQuarter': 1,\n",
    "            'endYear': datetime.now().year,\n",
    "            'endQuarter': 4\n",
    "        }\n",
    "        response = requests.get(url, headers=self.market_data.headers, params=params)\n",
    "        data_json = response.json()\n",
    "        if data_json:\n",
    "            eps = data_json[0].get('eps', 0)\n",
    "            return float(eps)\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    def _get_book_value(self, symbol: str) -> float:\n",
    "        \"\"\"Fetch Book Value per share\"\"\"\n",
    "        url = f'{self.market_data.base_url}/financial-data-and-ratio-by-symbol'\n",
    "        params = {\n",
    "            'symbol': symbol,\n",
    "            'startYear': datetime.now().year,\n",
    "            'startQuarter': 1,\n",
    "            'endYear': datetime.now().year,\n",
    "            'endQuarter': 4\n",
    "        }\n",
    "        response = requests.get(url, headers=self.market_data.headers, params=params)\n",
    "        data_json = response.json()\n",
    "        if data_json:\n",
    "            bvps = data_json[0].get('book_value_per_share', 0)\n",
    "            return float(bvps)\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    def _get_net_income(self, symbol: str) -> float:\n",
    "        \"\"\"Fetch Net Income\"\"\"\n",
    "        url = f'{self.market_data.base_url}/financial-data-and-ratio-by-symbol'\n",
    "        params = {\n",
    "            'symbol': symbol,\n",
    "            'startYear': datetime.now().year,\n",
    "            'startQuarter': 1,\n",
    "            'endYear': datetime.now().year,\n",
    "            'endQuarter': 4\n",
    "        }\n",
    "        response = requests.get(url, headers=self.market_data.headers, params=params)\n",
    "        data_json = response.json()\n",
    "        if data_json:\n",
    "            net_income = data_json[0].get('net_profit', 0)\n",
    "            return float(net_income)\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    def _get_equity(self, symbol: str) -> float:\n",
    "        \"\"\"Fetch Total Equity\"\"\"\n",
    "        url = f'{self.market_data.base_url}/financial-data-and-ratio-by-symbol'\n",
    "        params = {\n",
    "            'symbol': symbol,\n",
    "            'startYear': datetime.now().year,\n",
    "            'startQuarter': 1,\n",
    "            'endYear': datetime.now().year,\n",
    "            'endQuarter': 4\n",
    "        }\n",
    "        response = requests.get(url, headers=self.market_data.headers, params=params)\n",
    "        data_json = response.json()\n",
    "        if data_json:\n",
    "            total_equity = data_json[0].get('shareholders_equity', 0)\n",
    "            return float(total_equity)\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    def _calculate_rsi(self, prices: np.ndarray, period: int = 14) -> float:\n",
    "        \"\"\"Calculate Relative Strength Index\"\"\"\n",
    "        delta = np.diff(prices)\n",
    "        up = delta.clip(min=0)\n",
    "        down = -1 * delta.clip(max=0)\n",
    "        avg_gain = np.mean(up[-period:])\n",
    "        avg_loss = np.mean(down[-period:])\n",
    "        rs = avg_gain / avg_loss if avg_loss != 0 else 0\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        return rsi\n",
    "\n",
    "    def _calculate_macd(self, prices: np.ndarray) -> float:\n",
    "        \"\"\"Calculate Moving Average Convergence Divergence\"\"\"\n",
    "        exp1 = pd.Series(prices).ewm(span=12, adjust=False).mean()\n",
    "        exp2 = pd.Series(prices).ewm(span=26, adjust=False).mean()\n",
    "        macd = exp1 - exp2\n",
    "        signal = macd.ewm(span=9, adjust=False).mean()\n",
    "        return macd.iloc[-1] - signal.iloc[-1]\n",
    "\n",
    "    def _calculate_bollinger_bands(self, prices: np.ndarray, period: int = 20) -> Dict[str, float]:\n",
    "        \"\"\"Calculate Bollinger Bands\"\"\"\n",
    "        sma = np.mean(prices[-period:])\n",
    "        std = np.std(prices[-period:])\n",
    "        upper_band = sma + (2 * std)\n",
    "        lower_band = sma - (2 * std)\n",
    "        return {'upper_band': upper_band, 'lower_band': lower_band}\n",
    "\n",
    "    def generate_investment_report(self, file_path: str):\n",
    "        \"\"\"Generate comprehensive investment report\"\"\"\n",
    "        text = self.extract_text_from_pdf(file_path)\n",
    "        if not text:\n",
    "            print(\"ไม่สามารถวิเคราะห์เอกสารได้\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            industry, analysis = self.analyze_company(text)\n",
    "            self._display_results(industry, analysis)\n",
    "        except Exception as e:\n",
    "            print(f\"เกิดข้อผิดพลาดในการวิเคราะห์: {e}\")\n",
    "\n",
    "    def _display_results(self, industry: str, analysis: Dict[str, Any]):\n",
    "        \"\"\"Display results including plots\"\"\"\n",
    "        symbol = analysis.get('symbol', 'N/A')\n",
    "        financial_metrics = analysis.get('financial_metrics', None)\n",
    "        industry_analysis = analysis.get('industry_analysis', {})\n",
    "        ai_recommendations = analysis.get('ai_recommendations', {})\n",
    "        stock_data = analysis.get('stock_data', None)\n",
    "\n",
    "        # แสดงสัญลักษณ์หุ้น\n",
    "        print(f\"\\nสัญลักษณ์หุ้น: {symbol}\")\n",
    "\n",
    "        # แสดงประเภทธุรกิจ\n",
    "        print(f\"\\nประเภทธุรกิจ: {industry}\")\n",
    "\n",
    "        # แสดงคำแนะนำจาก AI (ถ้ามี)\n",
    "        print(\"\\nคำแนะนำจาก AI:\")\n",
    "        print(ai_recommendations.get('summary', 'ไม่มีคำแนะนำ'))\n",
    "\n",
    "        # แสดงหัวข้อที่ควรศึกษาเพิ่มเติม\n",
    "        print(\"\\nหัวข้อที่ควรศึกษาเพิ่มเติมเกี่ยวกับธุรกิจนี้:\")\n",
    "        for topic in industry_analysis.get('study_topics', []):\n",
    "            print(f\"- {topic}\")\n",
    "\n",
    "        # แสดงบริษัทในอุตสาหกรรมเดียวกันที่น่าสนใจ\n",
    "        print(\"\\nบริษัทในอุตสาหกรรมเดียวกันที่น่าสนใจ:\")\n",
    "        peer_companies = industry_analysis.get('peer_companies', [])\n",
    "        for company in peer_companies:\n",
    "            print(f\"- {company}\")\n",
    "\n",
    "        # แสดงกราฟราคาหุ้นของบริษัทในอุตสาหกรรมเดียวกัน\n",
    "        if stock_data:\n",
    "            self._plot_peer_companies([symbol] + peer_companies)\n",
    "        else:\n",
    "            print(\"ไม่มีข้อมูลราคาหุ้นสำหรับการแสดงกราฟ\")\n",
    "\n",
    "    def _plot_peer_companies(self, symbols: List[str]):\n",
    "        \"\"\"Plot stock prices of peer companies\"\"\"\n",
    "        print(\"\\nกำลังแสดงกราฟราคาหุ้นของบริษัทในอุตสาหกรรมเดียวกัน...\")\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for symbol in symbols:\n",
    "            data = self.market_data.get_stock_data(symbol, start_date='2022-01-01', end_date=datetime.now().strftime('%Y-%m-%d'))\n",
    "            if data:\n",
    "                plt.plot(data.dates, data.prices, label=symbol)\n",
    "        plt.title('Stock prices of companies in the same industry')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Price (THB)')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# การใช้งาน\n",
    "if __name__ == \"__main__\":\n",
    "    import torch\n",
    "\n",
    "    # ตั้งค่า API Key ของ SET SMART API\n",
    "    api_key = '65322b83-2986-4471-8efd-43a761d49aad'  # ใช้ API Key ที่คุณมี\n",
    "\n",
    "    # สร้างอินสแตนซ์ของ AdvancedFinancialAnalyzer\n",
    "    analyzer = AdvancedFinancialAnalyzer(api_key=api_key)\n",
    "\n",
    "    # ระบุเส้นทางไปยังไฟล์ PDF ของคุณ\n",
    "    file_path = \"k.pdf\"  # เปลี่ยนเป็นเส้นทางไฟล์ PDF ที่คุณต้องการวิเคราะห์\n",
    "\n",
    "    # ตรวจสอบว่าไฟล์ PDF มีอยู่หรือไม่\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"ไม่พบไฟล์ PDF ที่ระบุ: {file_path}\")\n",
    "    else:\n",
    "        analyzer.generate_investment_report(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6795b7b0-1d3b-4f01-9cb4-726576d81ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
